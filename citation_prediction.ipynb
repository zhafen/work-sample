{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8387ef29-28b4-46a3-9a84-d63b05eb13bb",
   "metadata": {},
   "source": [
    "This notebook is a narrative exploration of efforts to predict the number of citations per year a paper will receive,\n",
    "based on data available at time of publication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecbdf5b-05b6-4718-980d-ab8529dad09c",
   "metadata": {},
   "source": [
    "A full exploration of 25 different prediction models can be found [here](askfhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03520e6f-1704-4ffc-97bc-04da7c76beca",
   "metadata": {},
   "source": [
    "In this notebook I look to predict the number of citations a paper will received based upon\n",
    "* the words used in the abstract\n",
    "* physics-inspired semantic metrics (implemented in github.com/zhafen/cc and employed in Imel & Hafen in prep)\n",
    "* metadata (publishing journal, number of authors, number of pages, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e68668-19d2-4a08-99f8-f54a90063280",
   "metadata": {},
   "source": [
    "The raw code for this analysis can be [found here](https://github.com/zhafen/work-sample)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47cf7e-1495-462a-a9d8-511003524a97",
   "metadata": {},
   "source": [
    "I aimed to keep this work sample clean, so please reach out if you have questions about details I have not included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e40ba-dc4d-4378-8462-173cb8792eb5",
   "metadata": {},
   "source": [
    "You can jump to punchlines in the analysis via these links:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabbddae-5fa1-4a36-95cb-dea17077a45d",
   "metadata": {},
   "source": [
    "# User-Defined Parameters\n",
    "\n",
    "This dictionary contains various user-defined parameters. They will be explained when they are utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e78fd5-7589-4b45-ada3-50e968fbc1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = dict(\n",
    "    \n",
    "    # Data selection\n",
    "    data_dir = '/Users/zhafen/data/literature_topography',\n",
    "    region_number = 8,\n",
    "    convergence_degree = 3,\n",
    "    kernel_size = 16,\n",
    "    \n",
    "    # Features\n",
    "    numerical_variables = [\n",
    "        'age',\n",
    "        'references_count',\n",
    "        'page_count',\n",
    "        'log_author_count',\n",
    "    ],\n",
    "    categorical_variables = [\n",
    "        'journal_filtered',\n",
    "    ],\n",
    "    semantic_variables = [\n",
    "        'density',\n",
    "        'fringe_factor',\n",
    "    ],\n",
    "    \n",
    "    # Modeling\n",
    "    scoring = 'neg_root_mean_squared_error',\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f34309-46a4-4bc7-9f6a-0b959bd7e47b",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "I use publication abstracts and metadata pulled from the [NASA astrophysics data sytem](https://ui.adsabs.harvard.edu) via [the official API](https://ui.adsabs.harvard.edu/help/api/). The analyzed publications are from a randomly-chosen physics or astrophysics specialization.\n",
    "\n",
    "I externally preprocessed the abstract data with natural language processing (including tokenizing, stemming, and removing filler words), and each abstract has a corresponding bag-of-words representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb92437-05db-4492-9e67-5f5c2fef6b56",
   "metadata": {},
   "source": [
    "## Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b2e036-f122-47a3-89fe-0ba8fc3fe138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fd2943-e6ec-437f-b1f1-6c6fc9dab92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My custom non-relational-data-management package\n",
    "import verdict\n",
    "# My library for NLP analysis of scientific abstracts\n",
    "from cc import atlas, cartography, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c7fb1-35b2-4cb5-9fa4-5b6cf8f6c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load summary information.\n",
    "# I analyzed several randomly chosen specializations (\"regions\"), of which we are choosing an arbitrary one.\n",
    "summary_data_fp = os.path.join( pm['data_dir'], 'regions', 'regions_summary.h5' )\n",
    "data = verdict.Dict.from_hdf5( summary_data_fp )\n",
    "data_k = data['regions'][str(pm['region_number'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc76715-22b7-4a1a-8f06-fb3a6182adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for management of abstracts\n",
    "atlas_dir = os.path.join( pm['data_dir'], 'regions', 'region_{}'.format( pm['region_number'] ) )\n",
    "a = atlas.Atlas( atlas_dir, load_bibtex=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a554d7-e2a9-4ebe-a839-938a22911605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for analysis of vectorized abstracts\n",
    "projection = a.vectorize(\n",
    "    verbose = True,\n",
    ")\n",
    "c = cartography.Cartographer( **projection )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82a3143-48c7-4852-a005-2a4b942c8d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve metrics I calculated in external pre-processing\n",
    "metrics_fp = os.path.join( atlas_dir, 'topography_metrics.h5' )\n",
    "metrics = verdict.Dict.from_hdf5( metrics_fp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941e711-7a8a-4eb3-8aa7-fbf44aa6cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all the publications are viable for analysis.\n",
    "# I've saved information about what publications are viable, and here we load the identifying information.\n",
    "converged_kernel_size = data_k['converged_kernel_size'][:,-pm['convergence_degree']]\n",
    "converged = converged_kernel_size >= pm['kernel_size']\n",
    "publications = c.publications[converged]\n",
    "inds = np.arange( c.publications.size )[converged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630303a2-5ba7-4042-a5db-08466c023102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select word vectors\n",
    "v = c.vectors[inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674dcd56-924f-4eea-9079-460e75fe9dad",
   "metadata": {},
   "source": [
    "## Format into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f1f7e-4bf2-4c27-a659-c0e936efa30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9a73a-6d9c-48c9-b41b-8774911f2a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make into a dataframe, for convenience.\n",
    "df_data = copy.deepcopy( metrics )\n",
    "df_data['projection_ind'] = inds\n",
    "df = pd.DataFrame(\n",
    "    data = df_data._storage,\n",
    "    index=publications,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007e8d2-8d83-42d8-82dd-3399c44bddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop publications with no citations.\n",
    "# This catches all grant submissions, etc.\n",
    "df = df.loc[np.invert( np.isclose( df['citations_per_year'], 0. ) )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c619ad-3887-4834-be72-8a00997b8327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add logscale versions for some variables\n",
    "for column in [ 'density', 'citations_per_year', ]:\n",
    "    df['log_{}'.format( column )] = np.log10( df[column] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1129e064-678d-403a-8ce4-632d0935d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns for which we're missing abstract data (will show up as a nan in density)\n",
    "df.dropna(subset=['density',], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f20561-30cc-4caa-8a67-4f669110ebf4",
   "metadata": {},
   "source": [
    "## Derive or retrieve additional quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d75f1-d0b1-4bcb-9512-5b7384eaac78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4162776-d197-4656-86da-a446daa75a00",
   "metadata": {},
   "source": [
    "### ADS metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c619dc8-f7c9-4397-9846-c81dbc9e9c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_keys = []\n",
    "additional_data = {\n",
    "    'references_count': [],\n",
    "    'pages': [],\n",
    "    'author': [],\n",
    "    'journal': [],\n",
    "    'title': [],\n",
    "    'abstract_character_count': [],\n",
    "    'entry_date': [],\n",
    "}\n",
    "for citation_key, p in tqdm.tqdm( a.data.items() ):\n",
    "    \n",
    "    citation_keys.append( citation_key )\n",
    "    \n",
    "    # number of references\n",
    "    if p.references is None:\n",
    "        additional_data['references_count'].append( 0 )\n",
    "    else:\n",
    "        additional_data['references_count'].append( len( p.references ) )\n",
    "    \n",
    "    # Citation info\n",
    "    for key in [ 'pages', 'author', 'journal', 'title' ]:\n",
    "        try:\n",
    "            additional_data[key].append( p.citation[key] )\n",
    "        except KeyError:\n",
    "            additional_data[key].append( pd.NA )\n",
    "            \n",
    "    # Abstract\n",
    "    additional_data['abstract_character_count'].append( len( p.abstract_str() ) )\n",
    "    \n",
    "    # Entry date\n",
    "    additional_data['entry_date'].append( p.entry_date )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3c3e5-7124-4d09-9b1f-dd386727b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime\n",
    "additional_data['entry_date'] = pd.to_datetime( additional_data['entry_date'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599c111-433b-4c50-bf7b-8bef30a96a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join it onto the existing dataframe\n",
    "additional_df = pd.DataFrame( data=additional_data, index=citation_keys )\n",
    "df = df.join( additional_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1d39e0-468f-4e7a-92e7-664f9f499549",
   "metadata": {},
   "source": [
    "### Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280e3762-897c-42c0-8662-9c47ee5d3b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ind'] = np.arange( df.index.size )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8257eb5-9e42-47f4-b25e-317cb9f8d96c",
   "metadata": {},
   "source": [
    "### Page count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6596bc56-caa7-4d26-9ef5-cb8dbeb09341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data structurs\n",
    "df['page_count'] = np.full( len( df ), np.nan )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8fcce8-5f28-478c-a3ce-34af9d9ef21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the \"L\" in front of the pages for publications submitted to letters.\n",
    "pages_str = df['pages'].str.replace( 'L|P', '' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635f698a-3ec0-4947-80e0-93253b5c45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into two to take the difference\n",
    "pages_split = pages_str.str.split( '-', expand=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b1070c-ac3b-4afa-9a86-a1455f6aaef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the parseable data\n",
    "is_not_none = np.invert( pages_split[1].isnull() )\n",
    "is_numeric = pages_split[1].str.isnumeric()\n",
    "is_page_range = is_not_none & is_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fdafcd-3619-4d30-8737-f35e53972536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the valid page ranges, set the page count\n",
    "df.loc[is_page_range,'page_count'] = (\n",
    "    pages_split[1].loc[is_page_range].astype( int )\n",
    "    - pages_split[0].loc[is_page_range].astype( int )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049dfa8-bc07-4a71-a57a-761c93a3a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There can be one or two edge cases where there's a negative page count because of the formatting\n",
    "df.loc[df['page_count']<0,'page_count'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af818e59-3b6c-4c95-9b9c-eb95773f68e1",
   "metadata": {},
   "source": [
    "### Author count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e3bd0-bdb2-41f8-ae9b-721cfb6b1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author_count'] = df['author'].str.split( ' and ' ).apply( len )\n",
    "df['log_author_count'] = df['author_count'].apply( np.log10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feb7771-e0e6-4ead-82c8-9f0f105d4b40",
   "metadata": {},
   "source": [
    "### Title character count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82933473-b1ac-433b-b4c5-28a54d99cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_character_count'] = df['title'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5347d2e-779a-42e2-8a5c-5d178c112a55",
   "metadata": {},
   "source": [
    "### Journals, filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc703eb-34b6-4df2-8627-08cff24db58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most common journals\n",
    "df_grouped = df.groupby( 'journal' )\n",
    "journal_entry_count = df_grouped.size().sort_values( ascending=False )\n",
    "most_common_journals = journal_entry_count.iloc[:5].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fedc6de-68f2-4095-90de-8782db5022fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caa3514-35ad-49f7-a9fc-f4f02f35f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new column accordingly\n",
    "df['journal_filtered'] = df['journal'].copy()\n",
    "is_not_common_journal = np.invert( df['journal'].isin( most_common_journals ) )\n",
    "df.loc[is_not_common_journal,'journal_filtered'] = 'other'\n",
    "df.loc[df['journal'].isna(),'journal_filtered'] = 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17c2ca-0b97-495c-85f3-d0a76a71eb91",
   "metadata": {},
   "source": [
    "### Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51283a55-b723-4ceb-a8e0-ab824f1b99f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = c.vectors[df['projection_ind']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115ebe3c-914c-4480-bb86-0cadd93784cd",
   "metadata": {},
   "source": [
    "## Summarize data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d748ce8e-d06f-4e4b-ad3b-d4e49f74f715",
   "metadata": {},
   "source": [
    "There are two main data containers:\n",
    "`df`, which contains all the metadata and derived quantities,\n",
    "and `v`, which contains the word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef311bda-4779-46f7-a3f3-f0861a75052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d31a82-a3d1-4a0c-a564-4a3030e1a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37c724f-f880-4905-b9a1-ceaa7b9c77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaef67d-74ae-4356-8c0a-f7bedbd8f1d2",
   "metadata": {},
   "source": [
    "## Split testing and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d410795-d13c-49b7-94c3-c9bd48ebfedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b16ff0-12dd-4042-b326-9aa6c0274fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe\n",
    "df_train, df_test = train_test_split( df, test_size=0.2, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b07e53-7475-42be-94fd-67b5f904e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split word vector input\n",
    "v_train = v[df_train['ind']]\n",
    "v_test = v[df_test['ind']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143b1f1c-b5e5-4489-9b66-c5b13dabb333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split semantic input\n",
    "M_train = df_train[pm['semantic_variables']].values\n",
    "M_test = df_test[pm['semantic_variables']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae4f0bc-ca6a-499f-93ec-4c6c9939116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split metadata input\n",
    "X_train_df = df_train[pm['numerical_variables'] + pm['categorical_variables']]\n",
    "X_test_df = df_test[pm['numerical_variables'] + pm['categorical_variables']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f306152-dd29-4dac-88fd-61c2af636b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split output\n",
    "y_train = df_train['log_citations_per_year'].values\n",
    "y_test = df_test['log_citations_per_year'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caacaaf4-27d2-4098-acc3-e4ae3a24c91e",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "I've explored this dataset thoroughly elsewhere, so here I'll just visually summarize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd13b53-344e-428f-ab86-1a1ce6a24a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set_style( 'whitegrid' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165caa4-bc51-45bc-aeb2-2b3ec64c95eb",
   "metadata": {},
   "source": [
    "## Citations per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8354a-106e-41e5-ab84-5f1cfd23491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    df_train,\n",
    "    x = 'log_citations_per_year',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc856883-219e-495e-aeb3-b62a4525009f",
   "metadata": {},
   "source": [
    "## Numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666692e-2ed9-43b8-8c64-e266e9bc06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot = sns.pairplot(\n",
    "    df_train,\n",
    "    x_vars = pm['numerical_variables'],\n",
    "    y_vars = [ 'log_citations_per_year',],\n",
    "    kind = 'hist',\n",
    "    # plot_kws = { 'line_kws': { 'color': 'k', }, },\n",
    ")\n",
    "pairplot.axes[0,1].set_xlim( 0, 210 )\n",
    "pairplot.axes[0,2].set_xlim( 0, 40 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34740137-a6ee-4e2b-89ec-2e0c90eeb501",
   "metadata": {},
   "source": [
    "## Categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc6094-740b-4a8c-83f3-510f0c517328",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(\n",
    "    df_train,\n",
    "    x = 'journal_filtered',\n",
    "    y = 'log_citations_per_year',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b77df71-2c58-4cb2-a929-a946b3ea4802",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b070a45-fa9c-4b14-a9af-53c83d4e1f90",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09758df0-f2a7-483b-9e2d-866b9d2d00d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_validate, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162b6ad-0cc2-4b47-a71b-a749298f744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two things for our numerical variables:\n",
    "# Imputation of missing values and scaling by mean and std\n",
    "numerical_preprocessing = Pipeline(\n",
    "    [\n",
    "        ( 'impute', SimpleImputer( strategy='mean' ) ),\n",
    "        ( 'scale', StandardScaler() ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2bdd17-5577-4f36-b223-2469151c76bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for word vectors is just scaling\n",
    "vector_preprocessing = Pipeline(\n",
    "    [\n",
    "        ( 'scale', Normalizer() ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b30777-619d-462a-a9fe-5603b2aaf79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a subset of the numerical variables that I refer to as \"semantic\".\n",
    "# These variables contain metrics that measure the relationship of the words in a publication to words in other publications.\n",
    "semantic_preprocessing = Pipeline(\n",
    "    [\n",
    "        ( 'scale', StandardScaler() ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75fce9-9a65-41e4-8e99-6ae59ccdc365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the numerical preprocessing with onehot encoding for the categorical variable\n",
    "metadata_preprocessing = ColumnTransformer( [\n",
    "        ( 'numerical', numerical_preprocessing, pm['numerical_variables'] ),\n",
    "        ( 'onehot', OneHotEncoder(), pm['categorical_variables'] ),\n",
    "] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4434cd-c474-43a0-b2c1-176dbb174f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a kfold object for cross validation\n",
    "kfold = KFold(\n",
    "    n_splits = 5,\n",
    "    shuffle = True,\n",
    "    random_state = 1532\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc84c32-2691-45a7-afb3-955335ffd62a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A Baseline Model\n",
    "\n",
    "We use the mean log citations per year as the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e299af4-cdd0-4f5c-a3b0-bf421ee750e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e74d57-1f85-4c8d-ba83-c2d7bc45b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline( BaseEstimator ):\n",
    "    '''The baseline model is just the mean. We put it into a class\n",
    "    for full consistency with all future models.'''\n",
    "    \n",
    "    def fit( self, X , y):\n",
    "        \n",
    "        self.estimate = y.mean()\n",
    "        \n",
    "    def predict( self, X ):\n",
    "        \n",
    "        return np.full( X.shape[0], self.estimate )\n",
    "\n",
    "model = Baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c197ab5-80f5-450a-aab3-19f7efa91cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object for storing data\n",
    "crossvals = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce06be-12a6-4ad8-a26c-d4ccb120e0d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform and store cross validation\n",
    "crossvals['baseline'] = verdict.Dict( cross_validate(\n",
    "    estimator = model,\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    cv = kfold,\n",
    "    scoring = 'neg_root_mean_squared_error',\n",
    "    return_estimator = True,\n",
    ") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684e1930-7f1e-4c6b-83df-66c7b99f1738",
   "metadata": {},
   "source": [
    "Because the baseline is the mean we expect the RMSE for the individual folds to be similar to the standard deviation of the full sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5fd5a-d8fd-4d83-80a2-82fc2017e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "-crossvals['baseline']['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3910db-b536-4a34-998c-4f876ac123c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = y_train.mean()\n",
    "sample_std = y_train.std()\n",
    "sample_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd979aa3-f78c-4dd7-8f48-6b53e30efcdd",
   "metadata": {},
   "source": [
    "## A Naive Model: Simple Linear Regression\n",
    "\n",
    "For our first model we'll see if we can just use linear least squares regression with the word vectors as input.\n",
    "This is a pretty silly model: we're limited to linear order because of the high dimensionality of the word vectors, and it is unlikely that a single line can describe the citation relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe42a1-daf7-443c-a73e-e29d6c022a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f74f5e4-abbd-43dd-a482-34fbb0670cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "    [\n",
    "        ( 'preprocessing', vector_preprocessing ),\n",
    "        ( 'poly', PolynomialFeatures( degree=1 ) ),\n",
    "        ( 'reg', LinearRegression( fit_intercept=False ) ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b6841-330a-4f13-9f88-d32ede08693a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform and store cross validation\n",
    "crossvals['linear_regression'] = verdict.Dict( cross_validate(\n",
    "    estimator = model,\n",
    "    X = v_train,\n",
    "    y = y_train,\n",
    "    cv = kfold,\n",
    "    scoring = 'neg_root_mean_squared_error',\n",
    "    return_estimator = True,\n",
    ") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3c5b4-f7f5-4684-af25-e4a16b7a261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f962603-019f-44ee-8c46-3a81509e501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_swarmplot( crossval, y_lim=(sample_std-0.15, sample_std+0.15) ):    \n",
    "    \n",
    "    # Format data\n",
    "    df_data = -1. * verdict.Dict( crossvals ).inner_item( 'test_score' )\n",
    "    crossval_df = pd.DataFrame( df_data._storage ).melt( var_name='model', value_name='rmse' )\n",
    "    \n",
    "    # Visualize\n",
    "    fig = plt.figure( figsize=(len(df_data)*1.5, 3) )\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # Plot itself\n",
    "    sns.swarmplot(\n",
    "        data = crossval_df,\n",
    "        x = 'model',\n",
    "        y = 'rmse',\n",
    "        ax = ax,\n",
    "    )\n",
    "    \n",
    "    # Mark the analytic baseline value for comparison\n",
    "    ax.axhline(\n",
    "        sample_std,\n",
    "        color = '0.5',\n",
    "        linestyle = '--',\n",
    "        linewidth = 0.75,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel( 'model' )\n",
    "    ax.set_ylabel( r'RMSE in log_citations_per_year' )\n",
    "    \n",
    "    ax.set_ylim( y_lim )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da86f9-4567-470c-82d4-7f915fa38bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rmse_swarmplot( crossvals, y_lim=(sample_std-0.5, sample_std+0.5) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048836fc-7e9e-4a25-957f-73cd2af12457",
   "metadata": {},
   "source": [
    "No surprise, this model doesn't perform particularly well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca66ed4-5cd4-4fa1-9e4d-15d713328348",
   "metadata": {},
   "source": [
    "## A Basic Phenomenological Model: Random Forest\n",
    "\n",
    "For a more-sophisticated phenomenological description of the data, let's try a random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e774b2-48df-4672-bfde-dbe39ebab0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e85f76d-ac38-415b-b3f0-b3d72c64f534",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "    [\n",
    "        ( 'preprocessing', vector_preprocessing ),\n",
    "        ( 'reg', RandomForestRegressor( max_depth=3, n_estimators=200 ) ),    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290632bf-1343-418b-a3c0-715e78643725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform and store cross validation\n",
    "crossvals['random_forest'] = verdict.Dict( cross_validate(\n",
    "    estimator = model,\n",
    "    X = v_train,\n",
    "    y = y_train,\n",
    "    cv = kfold,\n",
    "    scoring = 'neg_root_mean_squared_error',\n",
    "    return_estimator = True,\n",
    ") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a6dd49-4cb3-40f1-b6d8-641b8030dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rmse_swarmplot( crossvals )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae55d9ac-cab0-4344-bee6-7c5e78279c1b",
   "metadata": {},
   "source": [
    "Better performance than the baseline! We're getting somewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360ca93e-5e47-4cb9-a5cc-ba73bfa91454",
   "metadata": {},
   "source": [
    "## A Better Phenomoenological Model: Gradient Boosting\n",
    "\n",
    "If the random forest model went well, how about a gradient boosting model with decision trees as the base?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25044341-7b2b-4211-a028-d8422cf1dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467cfeec-73e9-4aad-a608-b175de00ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "    [\n",
    "        ( 'preprocessing', vector_preprocessing ),\n",
    "        ( 'reg', GradientBoostingRegressor() ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21439189-049c-44f2-b0eb-1dda032a96fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform and store cross validation\n",
    "crossvals['grad_boost'] = verdict.Dict( cross_validate(\n",
    "    estimator = model,\n",
    "    X = v_train,\n",
    "    y = y_train,\n",
    "    cv = kfold,\n",
    "    scoring = 'neg_root_mean_squared_error',\n",
    "    return_estimator = True,\n",
    ") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb7329-8fe7-4d2b-ae2e-eed6d10c5768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's go ahead and drop the linear regression model so it's not distracting us.\n",
    "del crossvals['linear_regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc4f80b-5986-4e34-9abb-d94f11e69460",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rmse_swarmplot( crossvals, y_lim=(sample_std-0.2, sample_std+0.2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8630d2a8-353f-4311-b490-285aa0a12d1f",
   "metadata": {},
   "source": [
    "Great. We have a model that does noticeably better than the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c9cc9-0c3f-40d1-8505-255db94b230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'We can predict the number of citations to within a factor of ~{:.2g} on average.'.format( 10.**-crossvals['grad_boost']['test_score'].mean() ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444be596-35c4-4d83-820d-3a2d87ce9aa8",
   "metadata": {},
   "source": [
    "There is still a significant amount of error in the prediction: a factor of a few in predicting the number of citations per year. This is perhaps to be expected: it would be surprising if the main thing driving citation trends could be predicted simply via the words used, with no information about how those words relate to one another (e.g. via an N-gram language model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763545d3-562b-473c-bbe9-c6fd4d3aadcb",
   "metadata": {},
   "source": [
    "## An Informed Model: K Nearest Neighbors\n",
    "\n",
    "So far we've been treating the word vectors as generic data. To further improve our model, and add some explanatory power, let's make use of our knowledge about what the vectors _are_: the language used in a scientific abstract.\n",
    "\n",
    "Here's a simple hypothesis:\n",
    "The number of citations a paper receives correlates with the number of citations papers on similar topics (i.e. using similar words) receive. Fortunately this is a simple, well-defined model: the K Nearest Neighbors model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e84a18-20f0-4d98-9cfb-841048bc3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c236015-4fab-450f-ab19-b825c633253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(\n",
    "    [\n",
    "        ( 'preprocessing', vector_preprocessing ),\n",
    "        ( 'knn', KNeighborsRegressor( n_neighbors=32 ) ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3474bd37-6856-4e70-8a56-4ff8e8d24ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a parameter search for the number of neighbors to use\n",
    "param_grid = {\n",
    "    'knn__n_neighbors': [ 4, 16, 32, 64, 128, 256, ],\n",
    "}\n",
    "search = GridSearchCV( model, param_grid, )\n",
    "search.fit( v_train, df_train['log_citations_per_year'] )\n",
    "model = search.best_estimator_\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac82a6-a3f5-47e2-88d5-67dfefde21b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform and store cross validation\n",
    "crossvals['KNN'] = verdict.Dict( cross_validate(\n",
    "    estimator = model,\n",
    "    X = v_train,\n",
    "    y = y_train,\n",
    "    cv = kfold,\n",
    "    scoring = 'neg_root_mean_squared_error',\n",
    "    return_estimator = True,\n",
    ") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5f9382-dce9-4c97-aca7-bd4fe53b3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rmse_swarmplot( crossvals )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c7487-61be-44f8-b1f9-3b6d68687eda",
   "metadata": {},
   "source": [
    "KNN does comparably well to gradient boosting, but is much more interpretable!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d92b58-11ef-49c5-b5ee-855a187e8892",
   "metadata": {},
   "source": [
    "## Another Informed Model: Density and Asymmetry\n",
    "\n",
    "Related to K Nearest Neighbors, we can ask if the local geometry of the hyperspace is related to citations received. In particular, we'll define two metrics:\n",
    "\n",
    "density, which tracks the number of similar papers,\n",
    "$${\\rm density} = \\frac{K}{{\\rm distance\\,to\\,the\\,farthest\\,neighbor}}$$\n",
    "\n",
    "and \"fringe factor\", which tracks if a paper uses language in a new direction relative to existing similar papers.\n",
    "$${\\rm fringe\\,factor} = \\frac1K \\sum_{i=1}^{K} \\frac{\\vec v - \\vec v_i}{|\\vec v - \\vec v_i|} $$\n",
    "The concept of edginess comes from the concept of force balance.\n",
    "\n",
    "I calculated these quantities in preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304a0d6-d7dc-46b6-8da4-4b27007172bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    df_train,\n",
    "    x = 'density',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36dc601-e348-49d0-af8c-3ac2045a6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(\n",
    "    df_train,\n",
    "    x = 'fringe_factor',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2345c8-149b-4350-b735-45f9c9dce045",
   "metadata": {},
   "source": [
    "Most of the meaningful modeling is in the calculation of these two quantities, so we'll fit a simple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb8d65-29d7-4e46-98d1-31e17d045dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_model = Pipeline(\n",
    "    [\n",
    "        ( 'preprocessing', semantic_preprocessing ),\n",
    "        ( 'poly', PolynomialFeatures( degree=1 ) ),\n",
    "        ( 'reg', LinearRegression( fit_intercept=False ) ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d3157-f25c-4ead-973a-7ea96743f652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform and store cross validation\n",
    "crossvals['density_and_fringe_factor'] = verdict.Dict( cross_validate(\n",
    "    estimator = semantic_model,\n",
    "    X = M_train,\n",
    "    y = y_train,\n",
    "    cv = kfold,\n",
    "    scoring = 'neg_root_mean_squared_error',\n",
    "    return_estimator = True,\n",
    ") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c3ced-9ef3-4d1d-8390-4c14a377e17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rmse_swarmplot( crossvals )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a4c7fc-c075-4885-91c4-0a40ae4dedfb",
   "metadata": {},
   "source": [
    "Regressing on the explanatory variables of density and fringe factor does not give us the best model, but nevertheless holds some predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a6d483-5e0a-4409-aa55-6472c628f2fd",
   "metadata": {},
   "source": [
    "## A Model Utilizing Metadata\n",
    "\n",
    "Our analysis so far has been limited to the word content of the abstract. But presumably the number of citations received is a function of much more than the words employed. I have gathered a number of additional attributes for each publication, and we will regress onto those too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716a9eed-9e35-4b45-ae1f-737fb9bf8d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d895654a-2dce-495d-a1ea-d902f92d5356",
   "metadata": {},
   "source": [
    "I will regress with gradient boosting, but in exploratory modeling I discoverd that most other reasonable ML models perform similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d0321-abf6-46de-beaf-97de5496188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_model = Pipeline(\n",
    "    [\n",
    "        ( 'preprocessing', metadata_preprocessing ),\n",
    "        ( 'reg', GradientBoostingRegressor() ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d461b-b5c3-47e5-9ce3-309ecd390286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform and store cross validation\n",
    "crossvals['metadata'] = verdict.Dict( cross_validate(\n",
    "    estimator = metadata_model,\n",
    "    X = X_train_df,\n",
    "    y = y_train,\n",
    "    cv = kfold,\n",
    "    scoring = 'neg_root_mean_squared_error',\n",
    "    return_estimator = True,\n",
    ") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b9280-22a6-4121-b113-166520d35242",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rmse_swarmplot( crossvals )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bc913d-621f-4d11-83f2-58031d3a4102",
   "metadata": {},
   "source": [
    "The metadata contains a lot of information useful for predicting citations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e2c19f-fa85-456d-99e5-834284ef36bf",
   "metadata": {},
   "source": [
    "## A Neural Net\n",
    "\n",
    "We'll wrap up our individual models with a simple neural net regressed onto the word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7203f1af-e7eb-47c1-90a5-65ba59a52e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a133418-7cba-455a-8467-c8e0180e465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3883e5-59c0-4357-b3cf-834386c5bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple multilayer model\n",
    "neural_net = keras.models.Sequential()\n",
    "neural_net.add( keras.layers.Input( shape=(v_train.shape[1],) ) )\n",
    "neural_net.add( keras.layers.Dense( 16, activation='relu', ) )\n",
    "neural_net.add( keras.layers.Dense( 16, activation='relu' ) )\n",
    "neural_net.add( keras.layers.Dense( 1, ) )\n",
    "neural_net.compile( loss='mean_squared_error' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de9da0c-7c7c-4d5a-a30e-622c89bd8b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually build the model\n",
    "model = Pipeline(\n",
    "    [\n",
    "        ( 'preprocessing', vector_preprocessing ),\n",
    "        ( 'reg', neural_net ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d56645-49b4-4843-9dc9-af1deeea6ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform KFold cross validation\n",
    "# We could use the exact same code as before, but this allows a little additional control.\n",
    "crossvals['neural_net'] = {'test_score':[]}\n",
    "for train_index, test_index in kfold.split(v_train):\n",
    "        \n",
    "    # Fit and predict\n",
    "    model.fit( v_train[train_index].toarray(), y_train[train_index] )\n",
    "    log_cpy_pred = model.predict( v_train[test_index].toarray() )\n",
    "    \n",
    "    # Compare prediction\n",
    "    rmse = -np.sqrt( mean_squared_error( y_train[test_index], log_cpy_pred ) )\n",
    "    crossvals['neural_net']['test_score'].append( rmse )\n",
    "crossvals['neural_net']['test_score'] = np.array( crossvals['neural_net']['test_score'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfbea29-d4ce-417b-994d-2d48a1a0067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rmse_swarmplot( crossvals, y_lim=(sample_std-0.5, sample_std+0.5 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a28a60e-885c-463c-a9a1-2a10cd8837bf",
   "metadata": {},
   "source": [
    "While arguably the biggest blackbox of the considered models, the simple neural net performs remarkably well for predicting citations given the words used, at least on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f634a7-fcc3-405d-b148-eba1bcc6a131",
   "metadata": {},
   "source": [
    "## Putting it All Together: Voting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b2fd2-7bd0-4136-9427-77e517c3b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.ensemble import VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7040d1a2-91a1-4128-8fb7-799cf33dbf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine word vectors, semantic variables, and metadata into a single feature array\n",
    "X_train = metadata_preprocessing.fit_transform( X_train_df )\n",
    "n_sample = X_train.shape[0]\n",
    "n_X = X_train.shape[1]\n",
    "n_M = M_train.shape[1]\n",
    "n_v = v_train.shape[1]\n",
    "A_train = np.zeros( shape=(n_sample, n_X + n_M + n_v) )\n",
    "A_train[:,:n_X] = X_train\n",
    "A_train[:,n_X:n_X+n_M] = M_train\n",
    "A_train[:,n_X+n_M:] = vector_preprocessing.fit_transform( v_train ).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a15de1-d52a-47f2-a80a-bb882ee2015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build preprocessing functions to select either only the word vectors or the other features\n",
    "def select_word_vectors( A ):\n",
    "    \n",
    "    A_result = copy.copy( A )\n",
    "    A_result[:,:n_X+n_M] = 0.\n",
    "    \n",
    "    return A_result\n",
    "\n",
    "def select_semantic( A ):\n",
    "    \n",
    "    A_result = copy.copy( A )\n",
    "    A_result[:,:n_X] = 0.\n",
    "    A_result[:,n_X+n_M:] = 0.\n",
    "    \n",
    "    return A_result\n",
    "\n",
    "def select_metadata( A ):\n",
    "    \n",
    "    A_result = copy.copy( A )\n",
    "    A_result[:,n_X:] = 0.\n",
    "    \n",
    "    return A_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49fad6-a3c5-44fe-a5d8-0af0110ae7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the individual models.\n",
    "vector_grad_boosting = Pipeline(\n",
    "    [\n",
    "        ( 'select_word_vectors', FunctionTransformer( select_word_vectors ) ),\n",
    "        ( 'reg', GradientBoostingRegressor() ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "vector_knn = Pipeline(\n",
    "    [\n",
    "        ( 'select_word_vectors', FunctionTransformer( select_word_vectors ) ),\n",
    "        ( 'reg', KNeighborsRegressor( n_neighbors=search.best_params_['knn__n_neighbors'] ) ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_linear_regression = Pipeline(\n",
    "    [\n",
    "        ( 'select_semantic', FunctionTransformer( select_semantic ) ),\n",
    "        ( 'poly', PolynomialFeatures( degree=1 ) ),\n",
    "        ( 'reg', LinearRegression( fit_intercept=False ) ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "metadata_grad_boosting = Pipeline(\n",
    "    [\n",
    "        ( 'select_metadata', FunctionTransformer( select_metadata ) ),\n",
    "        ( 'reg', GradientBoostingRegressor() ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "neural_net = keras.models.Sequential()\n",
    "neural_net.add( keras.layers.Input( shape=(n_X+n_M+n_v,) ) )\n",
    "neural_net.add( keras.layers.Dense( 16, activation='relu', ) )\n",
    "neural_net.add( keras.layers.Dense( 16, activation='relu' ) )\n",
    "neural_net.add( keras.layers.Dense( 1, ) )\n",
    "neural_net.compile( loss='mean_squared_error' )\n",
    "vector_neural_net = Pipeline(\n",
    "    [\n",
    "        ( 'select_word_vectors', FunctionTransformer( select_word_vectors ) ),\n",
    "        ( 'reg', neural_net ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6a5f7-4826-486a-a075-c9a5da82f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VotingRegressor(\n",
    "    estimators = [\n",
    "        ( 'vector_grad_boosting', vector_grad_boosting ),\n",
    "        ( 'vector_knn', vector_knn ),\n",
    "        ( 'semantic_linear_regression', semantic_linear_regression ),\n",
    "        ( 'metadata_grad_boosting', metadata_grad_boosting ),\n",
    "        ( 'vector_neural_net', vector_neural_net ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f09a8f7-a98e-4dc2-bab9-63bfa85f6b26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform KFold cross validation\n",
    "# We could use the exact same code as before, but this allows a little additional control.\n",
    "crossvals['voting'] = {'test_score':[]}\n",
    "for train_index, test_index in tqdm.tqdm( kfold.split(A_train) ):\n",
    "        \n",
    "    # Fit and predict\n",
    "    vector_grad_boosting.fit( A_train[train_index], y_train[train_index] )\n",
    "    log_cpy_pred = vector_grad_boosting.predict( A_train[test_index] )\n",
    "    \n",
    "    # Compare prediction\n",
    "    rmse = -np.sqrt( mean_squared_error( y_train[test_index], log_cpy_pred ) )\n",
    "    crossvals['voting']['test_score'].append( rmse )\n",
    "crossvals['voting']['test_score'] = np.array( crossvals['voting']['test_score'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1712f2cf-3479-4aa9-8c9b-8d3f967efbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rmse_swarmplot( crossvals, y_lim=(sample_std-0.5, sample_std+0.5 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedbcbeb-298d-489f-9bba-c4bb62ea9274",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "\n",
    "* Even the best model can't predict citations that well. Our minimum RMSE suggests we will routinely misestimate by a factor of X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cbc6bf-d623-44fe-a678-299fb5196643",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "Utilized python packages include:\n",
    "* [ads](https://github.com/andycasey/ads)\n",
    "* nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847b232-37d3-46f6-bcfd-e725c28c7d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
