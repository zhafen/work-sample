{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8387ef29-28b4-46a3-9a84-d63b05eb13bb",
   "metadata": {},
   "source": [
    "This notebook is a narrative exploration of efforts to predict the number of citations per year a paper will receive,\n",
    "based on data available at time of publication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecbdf5b-05b6-4718-980d-ab8529dad09c",
   "metadata": {},
   "source": [
    "A full exploration of 25 different prediction models can be found [here](askfhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03520e6f-1704-4ffc-97bc-04da7c76beca",
   "metadata": {},
   "source": [
    "In this notebook I look to predict the number of citations a paper will received based upon\n",
    "* the words used in the abstract\n",
    "* physics-inspired semantic metrics (implemented in github.com/zhafen/cc and employed in Imel & Hafen in prep)\n",
    "* metadata (publishing journal, number of authors, number of pages, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e68668-19d2-4a08-99f8-f54a90063280",
   "metadata": {},
   "source": [
    "The raw code for this analysis can be [found here](https://github.com/zhafen/work-sample)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f47cf7e-1495-462a-a9d8-511003524a97",
   "metadata": {},
   "source": [
    "I aimed to keep this work sample clean, so please reach out if you have questions about details I have not included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e40ba-dc4d-4378-8462-173cb8792eb5",
   "metadata": {},
   "source": [
    "You can jump to punchlines in the analysis via these links:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabbddae-5fa1-4a36-95cb-dea17077a45d",
   "metadata": {},
   "source": [
    "# User-Defined Parameters\n",
    "\n",
    "This dictionary contains various user-defined parameters. They will be explained when they are utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0e78fd5-7589-4b45-ada3-50e968fbc1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm = dict(\n",
    "    # Data\n",
    "    data_dir = '/Users/zhafen/data/literature_topography',\n",
    "    region_number = 8,\n",
    "    convergence_degree = 3,\n",
    "    kernel_size = 16,\n",
    "    # Features\n",
    "    numerical_variables = [\n",
    "        'age',\n",
    "        'converged_kernel_size',\n",
    "        'density',\n",
    "        'fringe_factor',\n",
    "        'references_count',\n",
    "        'page_count',\n",
    "        'log_author_count',\n",
    "    ],\n",
    "    categorical_variables = [\n",
    "        'journal_filtered',\n",
    "    ],\n",
    "    semantic_variables = [\n",
    "        'density',\n",
    "        'fringe_factor',\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f34309-46a4-4bc7-9f6a-0b959bd7e47b",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "I use publication abstracts and metadata pulled from the [NASA astrophysics data sytem](https://ui.adsabs.harvard.edu) via [the official API](https://ui.adsabs.harvard.edu/help/api/). The analyzed publications are from a randomly-chosen physics or astrophysics specialization.\n",
    "\n",
    "I externally preprocessed the abstract data with natural language processing (including tokenizing, stemming, and removing filler words), and each abstract has a corresponding bag-of-words representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb92437-05db-4492-9e67-5f5c2fef6b56",
   "metadata": {},
   "source": [
    "## Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72fd2943-e6ec-437f-b1f1-6c6fc9dab92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# My custom non-relational-data-management package\n",
    "import verdict\n",
    "# My library for NLP analysis of scientific abstracts\n",
    "from cc import atlas, cartography, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c10c7fb1-35b2-4cb5-9fa4-5b6cf8f6c4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load summary information.\n",
    "# I analyzed several randomly chosen specializations (\"regions\"), of which we are choosing an arbitrary one.\n",
    "summary_data_fp = os.path.join( pm['data_dir'], 'regions', 'regions_summary.h5' )\n",
    "data = verdict.Dict.from_hdf5( summary_data_fp )\n",
    "data_k = data['regions'][str(pm['region_number'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bc76715-22b7-4a1a-8f06-fb3a6182adc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved atlas data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|█████████████████████████████████| 37311/37311 [00:01<00:00, 21616.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Class for management of abstracts\n",
    "atlas_dir = os.path.join( pm['data_dir'], 'regions', 'region_{}'.format( pm['region_number'] ) )\n",
    "a = atlas.Atlas( atlas_dir, load_bibtex=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1a554d7-e2a9-4ebe-a839-938a22911605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text...\n",
      "Using saved vectorized text...\n"
     ]
    }
   ],
   "source": [
    "# Class for analysis of vectorized abstracts\n",
    "projection = a.vectorize(\n",
    "    verbose = True,\n",
    ")\n",
    "c = cartography.Cartographer( **projection )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a82a3143-48c7-4852-a005-2a4b942c8d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve metrics I calculated in external pre-processing\n",
    "metrics_fp = os.path.join( atlas_dir, 'topography_metrics.h5' )\n",
    "metrics = verdict.Dict.from_hdf5( metrics_fp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b941e711-7a8a-4eb3-8aa7-fbf44aa6cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not all the publications are viable for analysis.\n",
    "# I've saved information about what publications are viable, and here we load the identifying information.\n",
    "converged_kernel_size = data_k['converged_kernel_size'][:,-pm['convergence_degree']]\n",
    "converged = converged_kernel_size >= pm['kernel_size']\n",
    "publications = c.publications[converged]\n",
    "inds = np.arange( c.publications.size )[converged]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88eca85-bca2-4067-b05b-528956226ec7",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "190d0efa-ecdf-40fc-9f2e-ca1ac7007672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce06be-12a6-4ad8-a26c-d4ccb120e0d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0011487 , 0.00084901, 0.00049782, 0.000458  , 0.00043535]),\n",
       " 'score_time': array([0.00037026, 0.00032496, 0.00028419, 0.00027323, 0.00028801]),\n",
       " 'estimator': [Baseline(), Baseline(), Baseline(), Baseline(), Baseline()],\n",
       " 'test_score': array([-0.42891344, -0.42412764, -0.38014943, -0.41732149, -0.44537275])}"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(\n",
    "    estimator = model,\n",
    "    X = x_t_df.values,\n",
    "    y = df_train['log_citations_per_year'].values,\n",
    "    cv = kfold,\n",
    "    scoring = 'neg_mean_squared_error',\n",
    "    return_estimator = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cbc6bf-d623-44fe-a678-299fb5196643",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "Utilized python packages include:\n",
    "* [ads](https://github.com/andycasey/ads)\n",
    "* nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847b232-37d3-46f6-bcfd-e725c28c7d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
